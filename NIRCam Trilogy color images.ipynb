{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trilogy color images\n",
    "\n",
    "[CEERS SDR3](https://ceers.github.io/sdr3.html) Simulated Data Release 3 NIRCam images in 6 filters:  \n",
    "https://ceers.github.io/sdr3.html\n",
    "\n",
    "[Trilogy](https://www.stsci.edu/~dcoe/trilogy/Intro.html) adapted for use in a Python 3 Jupyter notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from glob import glob\n",
    "from copy import deepcopy\n",
    "from os.path import join\n",
    "from os.path import expanduser\n",
    "home = expanduser(\"~\")\n",
    "\n",
    "import astropy  # version 4.2 is required to write magnitudes to ecsv file\n",
    "import astropy.io.fits as pyfits\n",
    "from astropy.io import fits\n",
    "import astropy.wcs as wcs\n",
    "from astropy.table import QTable, Table\n",
    "import astropy.units as u\n",
    "from astropy.visualization import make_lupton_rgb, SqrtStretch, LogStretch, LinearStretch, hist\n",
    "from astropy.visualization.mpl_normalize import ImageNormalize\n",
    "from astropy.coordinates import SkyCoord\n",
    "from astropy.stats import sigma_clipped_stats\n",
    "\n",
    "from importlib import reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib inline\n",
    "%matplotlib notebook\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "# https://matplotlib.org/tutorials/introductory/customizing.html\n",
    "#plt.style.use('/Users/dcoe/p/matplotlibrc.txt')\n",
    "plt.style.use('https://www.stsci.edu/~dcoe/matplotlibrc.txt')\n",
    "colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "from astropy.visualization.mpl_normalize import ImageNormalize\n",
    "from astropy.visualization import make_lupton_rgb, SqrtStretch, LogStretch, hist, simple_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trilogy\n",
    "\n",
    "from scipy.optimize import golden\n",
    "\n",
    "def da(k):\n",
    "    a1 = k * (x1 - x0) + 1\n",
    "    a2 = k * (x2 - x0) + 1\n",
    "    a1n = a1**n\n",
    "    a1n = np.abs(a1n)  # Don't want the solutions where a1 & a2 are both negative!\n",
    "    da1 = a1n - a2\n",
    "    k = np.abs(k)\n",
    "    if k == 0:\n",
    "        return da(1e-10)\n",
    "    else:\n",
    "        da1 = da1 / k  # To avoid solution k = 0!\n",
    "    return abs(da1)\n",
    "\n",
    "def imscale2(data, levels, y1):\n",
    "    # x0, x1, x2  YIELD  0, y1, 1,  RESPECTIVELY\n",
    "    # y1 = noiselum\n",
    "    global n, x0, x1, x2  # So that golden can use them\n",
    "    x0, x1, x2 = levels  \n",
    "    if y1 == 0.5:\n",
    "        k = (x2 - 2 * x1 + x0) / float(x1 - x0) ** 2\n",
    "    else:\n",
    "        n = 1 / y1\n",
    "        k = np.abs(golden(da))\n",
    "    r1 = np.log10( k * (x2 - x0) + 1)\n",
    "    v = np.ravel(data)\n",
    "    v = clip2(v, 0, None)\n",
    "    d = k * (v - x0) + 1\n",
    "    d = clip2(d, 1e-30, None)\n",
    "    z = np.log10(d) / r1\n",
    "    z = np.clip(z, 0, 1)\n",
    "    z.shape = data.shape\n",
    "    z = z * 255\n",
    "    z = z.astype(np.uint8)\n",
    "    return z\n",
    "\n",
    "def clip2(m, m_min=None, m_max=None):\n",
    "    if m_min == None:\n",
    "        m_min = np.min(m)\n",
    "    if m_max == None:\n",
    "        m_max = np.max(m)\n",
    "    return np.clip(m, m_min, m_max)\n",
    "\n",
    "\n",
    "# PREVIOUSLY in colorimage.py\n",
    "def set_levels(data, pp, stripneg=False, sortedalready=False):\n",
    "    if sortedalready:\n",
    "        vs = data\n",
    "    else:\n",
    "        print('sorting...')\n",
    "        vs = np.sort(data.flat)\n",
    "    if stripneg:  # Get rid of negative values altogether!\n",
    "        # This is the way I was doing it for a while\n",
    "        # Now that I'm not, resulting images should change (get lighter)\n",
    "        i = np.searchsorted(vs, 0)\n",
    "        vs = vs[i+1:]\n",
    "    else:  # Clip negative values to zero\n",
    "        vs = clip2(vs, 0, None)\n",
    "    ii = np.array(pp) * len(vs)\n",
    "    ii = ii.astype(int)\n",
    "    ii = np.clip(ii, 0, len(vs)-1)\n",
    "    levels = vs.take(ii)\n",
    "    #print ii, levels, vs, sort(vs)\n",
    "    return levels\n",
    "\n",
    "\n",
    "def determine_scaling(data, unsatpercent, noisesig=1, correctbias=True, noisesig0=2):\n",
    "    \"\"\"Determines data values (x0,x1,x2) which will be scaled to (0,noiselum,1)\"\"\"\n",
    "    # Robust mean & standard deviation\n",
    "    datasorted = data + 0\n",
    "    datasorted[np.isnan(datasorted)]=0  # set all nan values to zero\n",
    "    datasorted = np.sort(datasorted.flat)\n",
    "    if datasorted[0] == datasorted[-1]:  # data is all one value\n",
    "        levels = 0, 1, 100  # whatever\n",
    "    else:\n",
    "        data_mean, data_median, data_stddev = sigma_clipped_stats(datasorted)\n",
    "        m = data_mean\n",
    "        r = data_stddev\n",
    "        print('%g +/- %g' % (m, r))\n",
    "\n",
    "        if correctbias:\n",
    "            x0 = m - noisesig0 * r\n",
    "        else:\n",
    "            x0 = 0\n",
    "        x1 = m + noisesig * r\n",
    "        x2 = set_levels(datasorted, np.array([unsatpercent]), sortedalready=True)[0]\n",
    "        levels = x0, x1, x2\n",
    "    return levels\n",
    "\n",
    "def stamp_extent(data, sample_size=1000, dx=0, dy=0):\n",
    "    data_shape = data.shape\n",
    "    if len(data_shape) == 2:\n",
    "        ny, nx = data.shape\n",
    "    else:\n",
    "        ny, nx, three = data.shape\n",
    "    \n",
    "    yc = int(ny / 2)\n",
    "    xc = int(nx / 2)\n",
    "    #print(xc, yc)\n",
    "    #print(xc+dx, yc+dy)\n",
    "    \n",
    "    ylo = yc - sample_size / 2 + dy\n",
    "    yhi = yc + sample_size / 2 + dy\n",
    "\n",
    "    xlo = xc - sample_size / 2 + dx\n",
    "    xhi = xc + sample_size / 2 + dx\n",
    "    #print(xlo, xhi, ylo, yhi)\n",
    "    \n",
    "    ylo = int(np.clip(ylo, 0, ny))\n",
    "    yhi = int(np.clip(yhi, 0, ny))\n",
    "    xlo = int(np.clip(xlo, 0, nx))\n",
    "    xhi = int(np.clip(xhi, 0, nx))\n",
    "    #print(xlo, xhi, ylo, yhi)\n",
    "    return xlo, xhi, ylo, yhi\n",
    "\n",
    "def image_stamps(data, sample_size=1000, dx=0, dy=0):\n",
    "    xlo, xhi, ylo, yhi = stamp_extent(data, sample_size, dx, dy)\n",
    "    stamps = data[ylo:yhi,xlo:xhi]\n",
    "    return stamps\n",
    "\n",
    "image_stamp = image_stamps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#image_files_list = glob('../images/*.fits')\n",
    "#image_files_list = list(np.sort(image_files_list))\n",
    "\n",
    "field = 'ceers5'  # insert target name here\n",
    "filters = 'F115W F150W F200W F277W F356W F444W'.split()\n",
    "image_files_list = ['../images/%s_%s_sci.fits.gz' % (field, filt.lower()) for filt in filters]\n",
    "\n",
    "image_files_dict = {}\n",
    "for i, filt in enumerate(filters):\n",
    "    image_files_dict[filt] = image_files_list[i]\n",
    "    print(filt, image_files_dict[filt])\n",
    "    \n",
    "idata = 1  # index where science data is"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# View images (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 3, figsize=(9.5,6), sharex=True, sharey=True)\n",
    "\n",
    "for i, filt in enumerate(filters):\n",
    "    iy = i // 3\n",
    "    ix = i % 3\n",
    "    hdu = pyfits.open(image_files_list[i])\n",
    "    data = hdu[idata].data\n",
    "    norm = simple_norm(data, 'sqrt', min_percent=0.1, max_percent=99.9)\n",
    "    ax[iy,ix].imshow(data, origin='lower', interpolation='none', norm=norm, cmap='Greys_r')\n",
    "    ax[iy,ix].set_title(filt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample a region of the image and make a color stamp\n",
    "\n",
    "## Iterate until it looks good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input parameters\n",
    "\n",
    "#noiselum = 0.25\n",
    "#satpercent = 0.03\n",
    "noiselum = 0.10\n",
    "satpercent = 0.01\n",
    "unsatpercent = 1 - 0.01 * satpercent\n",
    "\n",
    "sample_size = 1000\n",
    "dx = -2500\n",
    "dy =  1000\n",
    "\n",
    "noisesig = 1\n",
    "correctbias = True\n",
    "noisesig0 = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrows = 2\n",
    "ncolumns = int(len(filters) / nrows)\n",
    "fig, ax = plt.subplots(nrows, ncolumns, figsize=(9.5,8), sharex=True, sharey=True)\n",
    "\n",
    "scaled_images = {}\n",
    "levels_all = {}\n",
    "my_stamp_extent = stamp_extent(data, sample_size, dx, dy)\n",
    "for i, filt in enumerate(filters):\n",
    "    data = fits.open(image_files_list[i])[idata].data\n",
    "    stamp = image_stamp(data, sample_size, dx, dy)\n",
    "    levels = determine_scaling(stamp.ravel(), unsatpercent, noisesig, correctbias, noisesig0)\n",
    "    scaled = imscale2(stamp, levels, noiselum)\n",
    "    levels_all[filt] = levels\n",
    "    scaled_images[filt] = scaled\n",
    "    ix = i % ncolumns\n",
    "    iy = int(i / ncolumns)\n",
    "    ax[iy,ix].imshow(scaled, origin='lower', interpolation='none', cmap='Greys_r', extent=my_stamp_extent)\n",
    "    ax[iy,ix].set_title(filt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Color image with 3 filters\n",
    "\n",
    "b = scaled_images['F115W']\n",
    "g = scaled_images['F200W']\n",
    "r = scaled_images['F444W']\n",
    "\n",
    "imrgb = np.array([r, g, b]).transpose((1,2,0)).astype(np.uint8)\n",
    "fig, ax = plt.subplots(1, 1, figsize=(9.5, 6))\n",
    "plt.imshow(imrgb, origin='lower', extent=my_stamp_extent) # (xlo,xhi,ylo,yhi))\n",
    "#matplotlib.image.imsave('stamp3.png', imrgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try a more complicated combination\n",
    "\n",
    "b = scaled_images['F115W'] * (1/4.) + scaled_images['F150W'] * (2/4.) + scaled_images['F200W'] * (1/4.)\n",
    "g = scaled_images['F150W'] * (1/4.) + scaled_images['F200W'] * (2/4.) + scaled_images['F277W'] * (1/4.)\n",
    "r = scaled_images['F277W'] * (1/4.) + scaled_images['F356W'] * (2/4.) + scaled_images['F444W'] * (1/4.) \n",
    "\n",
    "imrgb = np.array([r, g, b]).transpose((1,2,0)).astype(np.uint8)\n",
    "fig, ax = plt.subplots(1, 1, figsize=(9.5, 6))\n",
    "plt.imshow(imrgb, origin='lower', extent=my_stamp_extent) # (xlo,xhi,ylo,yhi))\n",
    "matplotlib.image.imsave('stamp6.png', imrgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 0:\n",
    "    # Lupton color image\n",
    "    color_image = make_lupton_rgb(r, g, b, Q=10, stretch=0.07)  # , minimum=(0.25, 0.11, 0.12))\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(9.5, 6))\n",
    "    plt.imshow(color_image, origin='lower')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Once you're happy with the color image stamp,\n",
    "# Create and save the color full image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_images = {}\n",
    "for i, filt in enumerate(filters):\n",
    "    levels = levels_all[filt]\n",
    "    print(filt, levels)\n",
    "    data = fits.open(image_files_list[i])[idata].data\n",
    "    scaled = imscale2(data, levels, noiselum)\n",
    "    scaled_images[filt] = scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = scaled_images['F115W'] * (1/4.) + scaled_images['F150W'] * (2/4.) + scaled_images['F200W'] * (1/4.)\n",
    "g = scaled_images['F150W'] * (1/4.) + scaled_images['F200W'] * (2/4.) + scaled_images['F277W'] * (1/4.)\n",
    "r = scaled_images['F277W'] * (1/4.) + scaled_images['F356W'] * (2/4.) + scaled_images['F444W'] * (1/4.) \n",
    "\n",
    "imrgb = np.array([r, g, b]).transpose((1,2,0)).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outfile = field + '_color.png'\n",
    "out_ext = ''\n",
    "if out_ext:\n",
    "    outfile = outfile.replace('.png', '_'+out_ext+'.png')\n",
    "    \n",
    "if os.path.exists(outfile):\n",
    "    print(outfile, 'EXISTS')\n",
    "else:\n",
    "    print('SAVING', outfile)\n",
    "    matplotlib.image.imsave(outfile, imrgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
